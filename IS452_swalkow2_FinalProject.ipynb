{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Processing Across Science Domains with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract:\n",
    "\n",
    "I want to do a half research and half coding project, where I use python to read in and parse different file types from difference science domains. For instance, some disciplines store everything in text files, others in json, others in specialized file types. I’d like to pick 3-5 science domains, find some free data sources, research how to handle the files and any metadata, and try to develop a program that will read in and make sense of the file contents for each dataset. By making sense of the contents, I mean the data should be formatted in either a human readable way or according to the domain standard.\n",
    "\n",
    "The purpose of this project is to:\n",
    "\n",
    "- Work on my file reading abilities in python\n",
    "- Investigate a systemic way of handling files in python from different perspectives\n",
    "- Understand how to handle metadata\n",
    "- Develop skills on how to handle different types of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- What domains will I focus on and how many?\n",
    "    - so far, three: Climate + Weather, Oceanography, Earthquakes\n",
    "    - considering doing a social science as well, so I don't just have physical science domains represented\n",
    "- What format is the secondary data coming in as?\n",
    "    - so far, csv, xml, geojson\n",
    "- What do can read this file type?\n",
    "    - base python, still working on this\n",
    "- What will the data look like? Dim, dtype, size, NAs, columns\n",
    "    - most likely, numbers, dates, descriptions\n",
    "- What do I need to do to change it?\n",
    "    - Additional libraries? Changing dtypes? Re-shaping? Calculations? Identifying useful columns?\n",
    "- What is the finished product? \n",
    "- What can I do with the finished product?\n",
    "    - thoughts so far- I want to get it to a state where it is ready to be visualized or analyzed but not acutally do those things. This is really going to depend on what visual or analysis is going to be done- so I'll find a use case and try to get the data to fit in that specific domain use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cilmate + Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://climate.weather.gc.ca/index_e.html\n",
    "- Historical data\n",
    "- Radar data\n",
    "- http://climate.weather.gc.ca/prods_servs/cdn_climate_summary_e.html\n",
    "- Monthly summaries\n",
    "- csv and xml downloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.esrl.noaa.gov/gmd/grad/surfrad/surf_check.php\n",
    "- Plot examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Research\n",
    "- Python resources\n",
    "- https://drclimate.wordpress.com/2016/10/04/the-weatherclimate-python-stack/\n",
    "- https://scitools.org.uk/iris/docs/latest/userguide/iris_cubes.html\n",
    "- xarray\n",
    "- https://arm-doe.github.io/pyart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastkml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/10/981bae93dfd4a43cd3a4d7702789d195484ddce142842fb505bd0919ef37/fastkml-0.11.tar.gz (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pygeoif (from fastkml)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/a7/fc5df91be602a66aaae21213e6eb9b9b8039c8074b6515c570b5110b9108/pygeoif-0.7.tar.gz\n",
      "Requirement already satisfied: python-dateutil in /anaconda3/lib/python3.6/site-packages (from fastkml) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil->fastkml) (1.11.0)\n",
      "Building wheels for collected packages: fastkml, pygeoif\n",
      "  Running setup.py bdist_wheel for fastkml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/swalkow/Library/Caches/pip/wheels/55/01/ea/6191eb73e0894743d02b33a2b1a570e85242844d810804fbf2\n",
      "  Running setup.py bdist_wheel for pygeoif ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/swalkow/Library/Caches/pip/wheels/60/6e/a7/3d3eef59ac84a86663d0f5c5a92091f5056e9aeb6588c4de34\n",
      "Successfully built fastkml pygeoif\n",
      "Installing collected packages: pygeoif, fastkml\n",
      "Successfully installed fastkml-0.11 pygeoif-0.7\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastkml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastkml as kml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Icethickness.kml', 'rt') as myfile:\n",
    "    doc=myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<kml xmlns=\"http://earth.google.com/kml/2.2\">\n",
      "<Document>\n",
      "  <name>Ice thickness</name>\n",
      "  <description><![CDATA[]]></description>\n",
      "  <Style id=\"style2\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style8\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style3\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style6\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style4\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style5\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style7\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style9\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style10\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style11\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Style id=\"style1\">\n",
      "    <IconStyle>\n",
      "      <Icon>\n",
      "        <href>http://maps.gstatic.com/intl/en_ca/mapfiles/ms/micons/blue-dot.png</href>\n",
      "      </Icon>\n",
      "    </IconStyle>\n",
      "  </Style>\n",
      "  <Placemark>\n",
      "    <name>Alert LT1</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style2</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-62.582283,82.490685,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Alert YLT</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style8</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-62.347015,82.483276,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Baker Lake</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style3</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-96.083328,64.300003,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Cambridge Bay</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style6</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-105.133331,69.116669,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Coral Harbour</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style4</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-83.262115,64.128128,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Eureka</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style5</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-85.950005,79.983330,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Hall Beach</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style7</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-81.233337,68.783333,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Inuvik</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style9</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-133.482788,68.304169,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Iqaluit</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style10</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-68.550003,63.750000,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Resolute</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style11</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-94.983368,74.716675,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "  <Placemark>\n",
      "    <name>Yellowknife</name>\n",
      "    <description><![CDATA[]]></description>\n",
      "    <styleUrl>#style1</styleUrl>\n",
      "    <Point>\n",
      "      <coordinates>-114.449997,62.466663,0.000000</coordinates>\n",
      "    </Point>\n",
      "  </Placemark>\n",
      "</Document>\n",
      "</kml>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_data = pd.read_excel('Ice_thickness.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table/Tableau 1: Explanation of Attributes/Explication des attributs</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column/\\nColonne</td>\n",
       "      <td>Title/Titre</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Station ID/ID de station</td>\n",
       "      <td>Station ID/ID de station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>Station Name/\\nNom de station</td>\n",
       "      <td>Station Name/Nom de station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>Relevant Date/\\nDate pertinente</td>\n",
       "      <td>The date when the ice measurement is taken / D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>Ice Thickness/\\nÉpaisseur de la glace</td>\n",
       "      <td>Measured ice thickness to the nearest whole ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>Snow Depth/Profondeur de la neige</td>\n",
       "      <td>Average snow depth to the nearest whole centim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>Surface Code/Code de surface</td>\n",
       "      <td>Surface features at the measurement site and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>Water Feature/Caractéristiques d'eau</td>\n",
       "      <td>The presence and orientation of cracks and lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H</td>\n",
       "      <td>Method of Observation/\\nMéthode d'observation</td>\n",
       "      <td>The method used to measure or estiamte the ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Table/Tableau 2: Surface Topography/Topographi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Code</td>\n",
       "      <td>Symbol/Symbole</td>\n",
       "      <td>Concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Smooth / Lisse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Rafted / Chevauchements</td>\n",
       "      <td>0 - 1/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/10 - 3/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10 - 10/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Ridged / Crêtes</td>\n",
       "      <td>0 - 1/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/10 - 3/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10 - 10/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>Hummocked / Hummocks</td>\n",
       "      <td>0 - 1/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/10 - 3/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10 - 10/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Table/Tableau 3: Leads and Cracks/Fissures et ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Code</td>\n",
       "      <td>Description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>No cracks or leads / Ni fissures ni chenaux</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Few cracks / Quelques fissures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>Numerous cracks / Nombreuses fissures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>Few leads / Quelques chenaux</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>Numerous leads / Nombreux chenaux</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Table/Tableau 4: Measurment method used/Méthod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Code</td>\n",
       "      <td>Description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>Visually / Visuelle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>Ice auger kit / Trousee de tarière</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>Hot wire / Fil chauffant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>Other means / Autre méthode</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Table/Tableau 1: Explanation of Attributes/Explication des attributs  \\\n",
       "0                                    Column/\\nColonne                     \n",
       "1                                                   A                     \n",
       "2                                                   B                     \n",
       "3                                                   C                     \n",
       "4                                                   D                     \n",
       "5                                                   E                     \n",
       "6                                                   F                     \n",
       "7                                                   G                     \n",
       "8                                                   H                     \n",
       "9                                                 NaN                     \n",
       "10  Table/Tableau 2: Surface Topography/Topographi...                     \n",
       "11                                               Code                     \n",
       "12                                                  0                     \n",
       "13                                                  1                     \n",
       "14                                                  2                     \n",
       "15                                                  3                     \n",
       "16                                                  4                     \n",
       "17                                                  5                     \n",
       "18                                                  6                     \n",
       "19                                                  7                     \n",
       "20                                                  8                     \n",
       "21                                                  9                     \n",
       "22                                                NaN                     \n",
       "23  Table/Tableau 3: Leads and Cracks/Fissures et ...                     \n",
       "24                                               Code                     \n",
       "25                                                  0                     \n",
       "26                                                  1                     \n",
       "27                                                  2                     \n",
       "28                                                  3                     \n",
       "29                                                  4                     \n",
       "30                                                NaN                     \n",
       "31  Table/Tableau 4: Measurment method used/Méthod...                     \n",
       "32                                               Code                     \n",
       "33                                                  0                     \n",
       "34                                                  1                     \n",
       "35                                                  2                     \n",
       "36                                                  3                     \n",
       "\n",
       "                                       Unnamed: 1  \\\n",
       "0                                     Title/Titre   \n",
       "1                        Station ID/ID de station   \n",
       "2                   Station Name/\\nNom de station   \n",
       "3                 Relevant Date/\\nDate pertinente   \n",
       "4           Ice Thickness/\\nÉpaisseur de la glace   \n",
       "5               Snow Depth/Profondeur de la neige   \n",
       "6                    Surface Code/Code de surface   \n",
       "7            Water Feature/Caractéristiques d'eau   \n",
       "8   Method of Observation/\\nMéthode d'observation   \n",
       "9                                             NaN   \n",
       "10                                            NaN   \n",
       "11                                 Symbol/Symbole   \n",
       "12                                 Smooth / Lisse   \n",
       "13                        Rafted / Chevauchements   \n",
       "14                                            NaN   \n",
       "15                                            NaN   \n",
       "16                                Ridged / Crêtes   \n",
       "17                                            NaN   \n",
       "18                                            NaN   \n",
       "19                           Hummocked / Hummocks   \n",
       "20                                            NaN   \n",
       "21                                            NaN   \n",
       "22                                            NaN   \n",
       "23                                            NaN   \n",
       "24                                    Description   \n",
       "25    No cracks or leads / Ni fissures ni chenaux   \n",
       "26                 Few cracks / Quelques fissures   \n",
       "27          Numerous cracks / Nombreuses fissures   \n",
       "28                   Few leads / Quelques chenaux   \n",
       "29              Numerous leads / Nombreux chenaux   \n",
       "30                                            NaN   \n",
       "31                                            NaN   \n",
       "32                                    Description   \n",
       "33                            Visually / Visuelle   \n",
       "34             Ice auger kit / Trousee de tarière   \n",
       "35                       Hot wire / Fil chauffant   \n",
       "36                    Other means / Autre méthode   \n",
       "\n",
       "                                           Unnamed: 2  \n",
       "0                                         Description  \n",
       "1                            Station ID/ID de station  \n",
       "2                         Station Name/Nom de station  \n",
       "3   The date when the ice measurement is taken / D...  \n",
       "4   Measured ice thickness to the nearest whole ce...  \n",
       "5   Average snow depth to the nearest whole centim...  \n",
       "6   Surface features at the measurement site and s...  \n",
       "7   The presence and orientation of cracks and lea...  \n",
       "8   The method used to measure or estiamte the ice...  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                      Concentration  \n",
       "12                                                NaN  \n",
       "13                                           0 - 1/10  \n",
       "14                                        2/10 - 3/10  \n",
       "15                                       4/10 - 10/10  \n",
       "16                                           0 - 1/10  \n",
       "17                                        2/10 - 3/10  \n",
       "18                                       4/10 - 10/10  \n",
       "19                                           0 - 1/10  \n",
       "20                                        2/10 - 3/10  \n",
       "21                                       4/10 - 10/10  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oceanography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://planetos.com/\n",
    "    - https://data.planetos.com/datasets/noaa_blended_sea_winds_clim_global\n",
    "    - gridded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Oceanography_JSON.json\") as f:\n",
    "    oj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['stats', 'entries'])\n"
     ]
    }
   ],
   "source": [
    "print(oj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([{'timeMin': '2000-01-15T00:00:00', 'count': 10, 'offset': 0, 'nextOffset': 10, 'timeMax': '2000-12-15T00:00:00'}, [{'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-01-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 5.937192916870117, 'v': 0.11202297359704971, 'w': 11.47663688659668}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-02-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 4.743940353393555, 'v': 0.5978343486785889, 'w': 10.427130699157715}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-03-16T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 3.575047731399536, 'v': -0.9129931330680847, 'w': 9.554756164550781}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-04-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 1.7229785919189453, 'v': -0.20937982201576233, 'w': 8.131121635437012}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-05-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 1.2662155628204346, 'v': 0.24141182005405426, 'w': 6.245646953582764}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-06-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 2.1460843086242676, 'v': 0.9425407648086548, 'w': 5.74296760559082}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-07-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 1.8298293352127075, 'v': 2.6227529048919678, 'w': 5.481565952301025}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-08-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 2.0974442958831787, 'v': 1.6682549715042114, 'w': 5.771543025970459}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-09-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 2.6578564643859863, 'v': 0.5432454347610474, 'w': 6.9756059646606445}}, {'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-10-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 2.8377273082733154, 'v': 0.14493028819561005, 'w': 8.257330894470215}}]])\n"
     ]
    }
   ],
   "source": [
    "print(oj.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'time_zlev_lat_lon', 'axes': {'time': '2000-01-15T00:00:00', 'z': 10.0, 'latitude': 49.5, 'longitude': -50.49999999999997}, 'data': {'u': 5.937192916870117, 'v': 0.11202297359704971, 'w': 11.47663688659668}}\n"
     ]
    }
   ],
   "source": [
    "print(oj['entries'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timeMin': '2000-01-15T00:00:00', 'count': 10, 'offset': 0, 'nextOffset': 10, 'timeMax': '2000-12-15T00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(oj['stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "oj_csv = pd.read_csv('Oceanography_csv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis:latitude</th>\n",
       "      <th>axis:longitude</th>\n",
       "      <th>axis:time</th>\n",
       "      <th>axis:z</th>\n",
       "      <th>data:u</th>\n",
       "      <th>data:v</th>\n",
       "      <th>data:w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-01-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.937193</td>\n",
       "      <td>0.112023</td>\n",
       "      <td>11.476637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-02-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.743940</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>10.427131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-03-16T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.575048</td>\n",
       "      <td>-0.912993</td>\n",
       "      <td>9.554756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-04-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.722979</td>\n",
       "      <td>-0.209380</td>\n",
       "      <td>8.131122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-05-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.266216</td>\n",
       "      <td>0.241412</td>\n",
       "      <td>6.245647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-06-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.146084</td>\n",
       "      <td>0.942541</td>\n",
       "      <td>5.742968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-07-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.829829</td>\n",
       "      <td>2.622753</td>\n",
       "      <td>5.481566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-08-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.097444</td>\n",
       "      <td>1.668255</td>\n",
       "      <td>5.771543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-09-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.657856</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>6.975606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-10-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.837727</td>\n",
       "      <td>0.144930</td>\n",
       "      <td>8.257331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-11-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.541229</td>\n",
       "      <td>0.367698</td>\n",
       "      <td>9.567712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49.5</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>2000-12-15T00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.330885</td>\n",
       "      <td>0.358779</td>\n",
       "      <td>10.558121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    axis:latitude  axis:longitude            axis:time  axis:z    data:u  \\\n",
       "0            49.5           -50.5  2000-01-15T00:00:00    10.0  5.937193   \n",
       "1            49.5           -50.5  2000-02-15T00:00:00    10.0  4.743940   \n",
       "2            49.5           -50.5  2000-03-16T00:00:00    10.0  3.575048   \n",
       "3            49.5           -50.5  2000-04-15T00:00:00    10.0  1.722979   \n",
       "4            49.5           -50.5  2000-05-15T00:00:00    10.0  1.266216   \n",
       "5            49.5           -50.5  2000-06-15T00:00:00    10.0  2.146084   \n",
       "6            49.5           -50.5  2000-07-15T00:00:00    10.0  1.829829   \n",
       "7            49.5           -50.5  2000-08-15T00:00:00    10.0  2.097444   \n",
       "8            49.5           -50.5  2000-09-15T00:00:00    10.0  2.657856   \n",
       "9            49.5           -50.5  2000-10-15T00:00:00    10.0  2.837727   \n",
       "10           49.5           -50.5  2000-11-15T00:00:00    10.0  3.541229   \n",
       "11           49.5           -50.5  2000-12-15T00:00:00    10.0  4.330885   \n",
       "\n",
       "      data:v     data:w  \n",
       "0   0.112023  11.476637  \n",
       "1   0.597834  10.427131  \n",
       "2  -0.912993   9.554756  \n",
       "3  -0.209380   8.131122  \n",
       "4   0.241412   6.245647  \n",
       "5   0.942541   5.742968  \n",
       "6   2.622753   5.481566  \n",
       "7   1.668255   5.771543  \n",
       "8   0.543245   6.975606  \n",
       "9   0.144930   8.257331  \n",
       "10  0.367698   9.567712  \n",
       "11  0.358779  10.558121  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oj_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://earthquake.usgs.gov/earthquakes/search/\n",
    "    - csv, xml or geojson\n",
    "    - timeseries\n",
    "    - https://stackoverflow.com/questions/42753745/how-can-i-parse-geojson-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geojson\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/34/bc3a65faabce27a7faa755ab08d811207a4fc438f77ef09c229fc022d778/geojson-2.4.1-py2.py3-none-any.whl\n",
      "Installing collected packages: geojson\n",
      "Successfully installed geojson-2.4.1\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Earthquake_GeoJson.json\") as f:\n",
    "    gj = geojson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'metadata', 'bbox', 'features'])\n"
     ]
    }
   ],
   "source": [
    "print(gj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"geometry\": {\"coordinates\": [-175.7399, -22.6763, 10], \"type\": \"Point\"}, \"id\": \"us700035gt\", \"properties\": {\"alert\": null, \"cdi\": null, \"code\": \"700035gt\", \"detail\": \"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us700035gt&format=geojson\", \"dmin\": 8.624, \"felt\": null, \"gap\": 116, \"ids\": \",us700035gt,\", \"mag\": 4.9, \"magType\": \"mb\", \"mmi\": null, \"net\": \"us\", \"nst\": null, \"place\": \"169km SSW of `Ohonua, Tonga\", \"rms\": 0.74, \"sig\": 369, \"sources\": \",us,\", \"status\": \"reviewed\", \"time\": 1555174874150, \"title\": \"M 4.9 - 169km SSW of `Ohonua, Tonga\", \"tsunami\": 0, \"type\": \"earthquake\", \"types\": \",geoserve,origin,phase-data,\", \"tz\": -720, \"updated\": 1555177471040, \"url\": \"https://earthquake.usgs.gov/earthquakes/eventpage/us700035gt\"}, \"type\": \"Feature\"}\n"
     ]
    }
   ],
   "source": [
    "features = gj['features'][0]\n",
    "print(features)\n",
    "# has the most data\n",
    "# what is useful to extract and transform?\n",
    "# coordinates, magnitude, magtype, place, sources, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureCollection\n",
      "\n",
      "{'generated': 1555179250000, 'url': 'https://earthquake.usgs.gov/fdsnws/event/1/query.geojson?starttime=2019-03-14%2000:00:00&endtime=2019-04-13%2023:59:59&minmagnitude=4.5&orderby=time', 'title': 'USGS Earthquakes', 'status': 200, 'api': '1.8.1', 'count': 468}\n",
      "\n",
      "[-179.8822, -64.6529, 2.8, 179.3101, 85.1725, 616.53]\n"
     ]
    }
   ],
   "source": [
    "print(gj[\"type\"])\n",
    "print()\n",
    "# metadata could be useful\n",
    "print(gj['metadata'])\n",
    "print()\n",
    "# could be useful for data visualization\n",
    "print(gj['bbox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Research\n",
    "- https://earthquake.usgs.gov/research/\n",
    "- https://github.com/NCAR/chords/wiki/JSON-vs-GeoJSON\n",
    "    - it's doesn't seem like there are any technical differences between JSON and GEOJSON\n",
    "    - GEOJSON seems to be streamlined way of storing geographic data, and is any data that is bound by coordinates in space\n",
    "    - so I can break this down like a JSON!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets:\n",
    "    - https://cooldatasets.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try twitter dataset- if can't be fixed find a new one\n",
    "# Find issue in the rows - find a way to exclude difficult rows\n",
    "# row 70 has an issue\n",
    "twitter_pd = pd.read_csv('twitter-hate-speech-classifier-DFE-a845520.csv', sep=',', nrows=69, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>does_this_tweet_contain_hate_speech</th>\n",
       "      <th>does_this_tweet_contain_hate_speech:confidence</th>\n",
       "      <th>_created_at</th>\n",
       "      <th>orig__golden</th>\n",
       "      <th>orig__last_judgment_at</th>\n",
       "      <th>orig__trusted_judgments</th>\n",
       "      <th>orig__unit_id</th>\n",
       "      <th>orig__unit_state</th>\n",
       "      <th>_updated_at</th>\n",
       "      <th>orig_does_this_tweet_contain_hate_speech</th>\n",
       "      <th>does_this_tweet_contain_hate_speech_gold</th>\n",
       "      <th>does_this_tweet_contain_hate_speech_gold_reason</th>\n",
       "      <th>does_this_tweet_contain_hate_speechconfidence</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853718217</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.6013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>615561535</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1666196150</td>\n",
       "      <td>Warning: penny boards will make you a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853718218</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>615561723</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>429512078</td>\n",
       "      <td>Fuck dykes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853718219</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>615562039</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>395623778</td>\n",
       "      <td>@sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853718220</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>615562068</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>497514685</td>\n",
       "      <td>\"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>853718221</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>615562488</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>588923553</td>\n",
       "      <td>@Zhugstubble You heard me bitch but any way I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments  _last_judgment_at  \\\n",
       "0  853718217     True      golden                  86                NaN   \n",
       "1  853718218     True      golden                  92                NaN   \n",
       "2  853718219     True      golden                  86                NaN   \n",
       "3  853718220     True      golden                  98                NaN   \n",
       "4  853718221     True      golden                  88                NaN   \n",
       "\n",
       "                 does_this_tweet_contain_hate_speech  \\\n",
       "0  The tweet uses offensive language but not hate...   \n",
       "1                     The tweet contains hate speech   \n",
       "2                     The tweet contains hate speech   \n",
       "3                     The tweet contains hate speech   \n",
       "4  The tweet uses offensive language but not hate...   \n",
       "\n",
       "   does_this_tweet_contain_hate_speech:confidence  _created_at  orig__golden  \\\n",
       "0                                          0.6013          NaN          True   \n",
       "1                                          0.7227          NaN          True   \n",
       "2                                          0.5229          NaN          True   \n",
       "3                                          0.5184          NaN          True   \n",
       "4                                          0.5185          NaN          True   \n",
       "\n",
       "   orig__last_judgment_at  orig__trusted_judgments  orig__unit_id  \\\n",
       "0                     NaN                        0      615561535   \n",
       "1                     NaN                        0      615561723   \n",
       "2                     NaN                        0      615562039   \n",
       "3                     NaN                        0      615562068   \n",
       "4                     NaN                        0      615562488   \n",
       "\n",
       "  orig__unit_state  _updated_at orig_does_this_tweet_contain_hate_speech  \\\n",
       "0           golden          NaN           The tweet contains hate speech   \n",
       "1           golden          NaN           The tweet contains hate speech   \n",
       "2           golden          NaN           The tweet contains hate speech   \n",
       "3           golden          NaN           The tweet contains hate speech   \n",
       "4           golden          NaN           The tweet contains hate speech   \n",
       "\n",
       "            does_this_tweet_contain_hate_speech_gold  \\\n",
       "0  The tweet contains hate speech\\nThe tweet uses...   \n",
       "1  The tweet contains hate speech\\nThe tweet uses...   \n",
       "2  The tweet contains hate speech\\nThe tweet uses...   \n",
       "3  The tweet contains hate speech\\nThe tweet uses...   \n",
       "4  The tweet contains hate speech\\nThe tweet uses...   \n",
       "\n",
       "   does_this_tweet_contain_hate_speech_gold_reason  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   does_this_tweet_contain_hate_speechconfidence    tweet_id  \\\n",
       "0                                              1  1666196150   \n",
       "1                                              1   429512078   \n",
       "2                                              1   395623778   \n",
       "3                                              1   497514685   \n",
       "4                                              1   588923553   \n",
       "\n",
       "                                          tweet_text  \n",
       "0       Warning: penny boards will make you a faggot  \n",
       "1                                         Fuck dykes  \n",
       "2  @sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...  \n",
       "3  \"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...  \n",
       "4  @Zhugstubble You heard me bitch but any way I'...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x1101a03c8>\n",
      "['_unit_id', '_golden', '_unit_state', '_trusted_judgments', '_last_judgment_at', 'does_this_tweet_contain_hate_speech', 'does_this_tweet_contain_hate_speech:confidence', '_created_at', 'orig__golden', 'orig__last_judgment_at', 'orig__trusted_judgments', 'orig__unit_id', 'orig__unit_state', '_updated_at', 'orig_does_this_tweet_contain_hate_speech', 'does_this_tweet_contain_hate_speech_gold', 'does_this_tweet_contain_hate_speech_gold_reason', 'does_this_tweet_contain_hate_speechconfidence', 'tweet_id', 'tweet_text']\n",
      "['853718217', 'TRUE', 'golden', '86', '', 'The tweet uses offensive language but not hate speech', '0.6013', '', 'TRUE', '', '0', '615561535', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '1666196150', 'Warning: penny boards will make you a faggot']\n",
      "['853718218', 'TRUE', 'golden', '92', '', 'The tweet contains hate speech', '0.7227', '', 'TRUE', '', '0', '615561723', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '429512078', 'Fuck dykes']\n",
      "['853718219', 'TRUE', 'golden', '86', '', 'The tweet contains hate speech', '0.5229', '', 'TRUE', '', '0', '615562039', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '395623778', '@sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandonernandez @bootyacid at least i dont look like jefree starr faggot']\n",
      "['853718220', 'TRUE', 'golden', '98', '', 'The tweet contains hate speech', '0.5184', '', 'TRUE', '', '0', '615562068', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '497514685', '\"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkillah Is a fag\" jackie jealous\" Neeeee']\n",
      "['853718221', 'TRUE', 'golden', '88', '', 'The tweet uses offensive language but not hate speech', '0.5185', '', 'TRUE', '', '0', '615562488', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '588923553', \"@Zhugstubble You heard me bitch but any way I'm back th texas so wtf u talking about bitch ass nigga\"]\n",
      "['853718222', 'TRUE', 'golden', '93', '', 'The tweet contains hate speech', '0.8816', '', 'TRUE', '', '0', '615562522', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech', '', '1', '203816023', '@elaynay your a dirty terrorist and your religion is a fucking joke, you go around screaming Allah akbar doing terrorist shit. Dirty faggot.']\n",
      "['853718223', 'TRUE', 'golden', '88', '', 'The tweet contains hate speech', '0.5207', '', 'TRUE', '', '0', '615562768', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '1945524931', 'RT @ivanrabago_: @_WhitePonyJr_ looking like faggots?']\n",
      "['853718224', 'TRUE', 'golden', '90', '', 'The tweet contains hate speech', '0.5619', '', 'TRUE', '', '0', '615563304', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '210818115', \"Well I thought you knew actually RT @KingHorseDick: Man why y'all didn't tell me I was a dick riding ass faggot? Y'all not real &#128557;&#128557;&#128557;&#128557;&#128557;&#128557;\"]\n",
      "['853718225', 'TRUE', 'golden', '92', '', 'The tweet uses offensive language but not hate speech', '0.6419', '', 'TRUE', '', '0', '615563419', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '342826948', '@Stonisnipezz I know. It was a joke, faggot.']\n",
      "['853718226', 'TRUE', 'golden', '95', '', 'The tweet uses offensive language but not hate speech', '0.6407', '', 'TRUE', '', '0', '615563491', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '818430446', \"I'm tired of people saying I look like my brother &amp; calling me Deondre' like serious Succ My Ass fag asses\"]\n",
      "['853718227', 'TRUE', 'golden', '84', '', 'The tweet contains hate speech', '0.7619', '', 'TRUE', '', '0', '615563519', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '105105254', '#VoteBlue2014 Yeah. CUZ 8 million people in faggot ass #newyork are #chickenshit JEWS&gt; FUCK THEM right? Fuck Bibi Netanyahu. RIGHT?']\n",
      "['853718228', 'TRUE', 'golden', '91', '', 'The tweet contains hate speech', '0.5606', '', 'TRUE', '', '0', '615563660', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '203816023', '@AndreBerto word is you use roids, stupid hypocrite lying faggot.']\n",
      "['853718229', 'TRUE', 'golden', '94', '', 'The tweet contains hate speech', '0.8435', '', 'TRUE', '', '0', '615563683', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech', '', '1', '395623778', 'I hate faggots like you']\n",
      "['853718230', 'TRUE', 'golden', '86', '', 'The tweet contains hate speech', '0.8414', '', 'TRUE', '', '0', '615563702', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech', '', '1', '1488430273', '@MoriTaheripour shut up nigger whore! Hope u get raped by one of those animals. Might change your tune.']\n",
      "['853718231', 'TRUE', 'golden', '90', '', 'The tweet contains hate speech', '0.8826', '', 'TRUE', '', '0', '615563784', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech', '', '1', '1488430273', '@Oprah @3LWTV Fuck you nigger sheboon. Hope you r strung up like all niggers should be. WHITEPOWER. #1488']\n",
      "['853718232', 'TRUE', 'golden', '88', '', 'The tweet contains hate speech', '0.762', '', 'TRUE', '', '0', '615563879', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '218965679', 'They used to tie both ends of a niggers legs to 2 different horses and beat him as the horses spread until his legs break ... Smh']\n",
      "['853718233', 'TRUE', 'golden', '93', '', 'The tweet contains hate speech', '0.6833', '', 'TRUE', '', '0', '615563921', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '2472721168', \"Good night fags and fagettes (that's the female version of fags like fag-ettes to make it female) I hate you all.\"]\n",
      "['853718234', 'TRUE', 'golden', '88', '', 'The tweet uses offensive language but not hate speech', '0.5204', '', 'TRUE', '', '0', '615564197', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '79140662', 'I cant stand no crybaby ass nigga. If you gonna act like a bitch I will leave yo ass after I instavideo yo stupid lookin ass']\n",
      "['853718235', 'TRUE', 'golden', '95', '', 'The tweet contains hate speech', '0.641', '', 'TRUE', '', '0', '615564342', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '2373785059', \"RT @nerdkiller669: @ShinSnipes no you're a nigger\"]\n",
      "['853718236', 'TRUE', 'golden', '90', '', 'The tweet uses offensive language but not hate speech', '0.6419', '', 'TRUE', '', '0', '615564392', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '325412982', '\"I\\'ll fuck you til you love me faggot\" - Mike Tyson']\n",
      "['853718237', 'TRUE', 'golden', '91', '', 'The tweet contains hate speech', '0.7608', '', 'TRUE', '', '0', '615565207', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '1488430273', \"@OxbloodStomper @PalePixie88 @SlaveCatcher88 what's your problem? Don't u know Jews control niggers? Read a book or two.\"]\n",
      "['853718238', 'TRUE', 'golden', '92', '', 'The tweet contains hate speech', '0.9221', '', 'TRUE', '', '0', '615565821', 'golden', '', 'The tweet contains hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '29978724', 'I fucking hate you niggers bruh... http://t.co/OeTK4f94BO']\n",
      "['853718239', 'TRUE', 'golden', '92', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561124', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '1165002522', 'RT @Fact: Some species of birds have been known to hold funerals for their deceased.']\n",
      "['853718240', 'TRUE', 'golden', '91', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561133', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '283696380', \"I remember Draft prom night, my dress wouldn't zip up and I was bawling my eyes out and screaming I didn't want to go... So funny. Haha.\"]\n",
      "['853718241', 'TRUE', 'golden', '90', '', 'The tweet is not offensive', '0.9218', '', 'TRUE', '', '0', '615561137', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '190108253', \"Damn Eli. That's just ruff. I'm not even gonna trash talk that one. Get your game together Eli. You're a good QB. Stop with the TO's\"]\n",
      "['853718242', 'TRUE', 'golden', '93', '', 'The tweet is not offensive', '0.9204', '', 'TRUE', '', '0', '615561147', 'golden', '', 'The tweet is not offensive', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '100480088', 'Also, Happy Armistice Day, anachronists!\\n\\n&#8220;The Hun is either at your throat or at your feet.&#8221; - Churchill']\n",
      "['853718243', 'TRUE', 'golden', '88', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561165', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '430017793', \"@ExpSelf A friend suggested I dress as a Fairy for a Halloween party we're attending...I'm thinking more Wizardess of course. :)\"]\n",
      "['853718244', 'TRUE', 'golden', '94', '', 'The tweet is not offensive', '0.8388', '', 'TRUE', '', '0', '615561179', 'golden', '', 'The tweet is not offensive', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '1232408766', 'RT @BitchPlsComedy: apparently &#8220;bae&#8221; means &#8220;before anyone else&#8221; i always thought it was a ghetto word for &#8220;babe&#8221;']\n",
      "['853718245', 'TRUE', 'golden', '91', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561181', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '2472721168', '@RiotSupport so I was suspended for a day because of a random lag spikes that force me to close the client and relog and suspended. GG']\n",
      "['853718246', 'TRUE', 'golden', '90', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561183', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '24233192', '#Flyers w/ some moxy! Big comeback again!!! Major penalty killed the Caps.Great game. 5 cases of #tastycakes']\n",
      "['853718247', 'TRUE', 'golden', '87', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561190', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '266932764', 'pollo&#128523;&#128523;&#128523;']\n",
      "['853718248', 'TRUE', 'golden', '93', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561192', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '82977912', '#YouWillNotBeTakenSeriouslyIf you wear shorty shorts and fuzzy boots in negative degree weather.']\n",
      "['853718249', 'TRUE', 'golden', '95', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561195', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '112078104', \"@LeeLee0474 Awww, that's cute! My niece's guinea pig crawled up her dad's pants &amp; well I don't think I need to finish this sentence.lol\"]\n",
      "['853718250', 'TRUE', 'golden', '93', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561208', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '282629614', 'Then gave the ole uncle Charlie to mr Ortiz #nyy @DBetances50']\n",
      "['853718251', 'TRUE', 'golden', '91', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561214', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '387922273', 'RT @YepillPosts: If I had a dollar for every time I died on flappy bird http://t.co/pj8QSBTe2L']\n",
      "['853718252', 'TRUE', 'golden', '96', '', 'The tweet is not offensive', '0.8391', '', 'TRUE', '', '0', '615561215', 'golden', '', 'The tweet is not offensive', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '454364450', \"RT @kelter1: The fact that Kim Kardashian's app may make $200 million makes me wish we can speed up the process of having the apes take ove&#8230;\"]\n",
      "['853718253', 'TRUE', 'golden', '97', '', 'The tweet is not offensive', '0.9602', '', 'TRUE', '', '0', '615561236', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '727463083', 'I play for keeps you play wit me its gon be yellow tape! #200']\n",
      "['853718254', 'TRUE', 'golden', '94', '', 'The tweet is not offensive', '0.5209', '', 'TRUE', '', '0', '615561241', 'golden', '', 'The tweet is not offensive', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '61463715', \"@LastProtestants @stomponato @delschilling You're an idiot.\"]\n",
      "['853718255', 'TRUE', 'golden', '96', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561245', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '105723640', 'A mock up of my wedding photos http://t.co/qgPtAmfjPA']\n",
      "['853718256', 'TRUE', 'golden', '87', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561247', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '823888934', '&#8220;@fhairhead: Only in Vermont is it big news that our govern got a buck #vermontproblems&#8221;']\n",
      "['853718257', 'TRUE', 'golden', '93', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561259', 'golden', '', 'The tweet is not offensive', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '1702441442', 'Sitting alone watching White Chicks, no pants, fuzzy blankets, tea || turn up']\n",
      "['853718258', 'TRUE', 'golden', '90', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561260', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '1330165770', \"I want to go to a haunted house maybe get possesed y'know just to see if ghosts are real &#128561;&#128128;\"]\n",
      "['853718259', 'TRUE', 'golden', '92', '', 'The tweet is not offensive', '1', '', 'TRUE', '', '0', '615561270', 'golden', '', 'The tweet is not offensive', 'The tweet is not offensive', '', '1', '526955067', '$10 bucks the Browns get Johnny ! &#128527;&#128588;&#128175;']\n",
      "['853718260', 'TRUE', 'golden', '89', '', 'The tweet uses offensive language but not hate speech', '1', '', 'TRUE', '', '0', '615562149', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech', '', '1', '1420944386', 'I was with a bitch with a mustash for a year and a half? Wtf is wrong itch me']\n",
      "['853718261', 'TRUE', 'golden', '98', '', 'The tweet uses offensive language but not hate speech', '0.962', '', 'TRUE', '', '0', '615562150', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '93231924', 'RT @skythedon: Huge ass, small waist &amp; okay face &amp; bitches really think they famous']\n",
      "['853718262', 'TRUE', 'golden', '92', '', 'The tweet uses offensive language but not hate speech', '0.9613', '', 'TRUE', '', '0', '615562151', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech', '', '1', '427712556', 'Bobby flay in this bitch']\n",
      "['853718263', 'TRUE', 'golden', '89', '', 'The tweet uses offensive language but not hate speech', '0.8018', '', 'TRUE', '', '0', '615562154', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech', '', '1', '433447525', \"I'm never gonna be ok with my nigga around alot of bitches while with his boys. Cause I was once that female your boys put you on !!\"]\n",
      "['853718264', 'TRUE', 'golden', '88', '', 'The tweet uses offensive language but not hate speech', '0.9618', '', 'TRUE', '', '0', '615562157', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech', '', '1', '481792090', 'Where the bad bitches at? Lol @Vbomb20']\n",
      "['853718265', 'TRUE', 'golden', '94', '', 'The tweet uses offensive language but not hate speech', '0.6837', '', 'TRUE', '', '0', '615562158', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet contains hate speech\\nThe tweet uses offensive language but not hate speech', '', '1', '716449315', \"RT @KayciMalynn: I just can't help but to hate you. Even though you never intentionally did anything to me you're still a cunt. #girllogic\"]\n",
      "['853718266', 'TRUE', 'golden', '93', '', 'The tweet uses offensive language but not hate speech', '0.9608', '', 'TRUE', '', '0', '615562159', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '343926738', \"RT @HBCUfessions: You females overlook us geeks. When I take these glasses off, I'm no longer Clark Kent. I go superman in that pussy. - FA&#8230;\"]\n",
      "['853718267', 'TRUE', 'golden', '89', '', 'The tweet uses offensive language but not hate speech', '0.8021', '', 'TRUE', '', '0', '615562161', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '375424417', 'RT @macktology101: \"Sunday funday\" hoe quotes']\n",
      "['853718268', 'TRUE', 'golden', '88', '', 'The tweet uses offensive language but not hate speech', '0.882', '', 'TRUE', '', '0', '615562162', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech', '', '1', '590353389', 'I know these bitches did not leave me, AGAIN. #FuckEverybody']\n",
      "['853718269', 'TRUE', 'golden', '91', '', 'The tweet uses offensive language but not hate speech', '0.9226', '', 'TRUE', '', '0', '615562163', 'golden', '', 'The tweet uses offensive language but not hate speech', 'The tweet uses offensive language but not hate speech\\nThe tweet is not offensive', '', '1', '25189083', 'RT @JoeBudden: Young, attractive, successful, supportive, faithful man w his own everything..u think bringing solely pussy to the table is &#8230;']\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 5123: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-da88d4182ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mline_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 5123: invalid start byte"
     ]
    }
   ],
   "source": [
    "with open('twitter-hate-speech-classifier-DFE-a845520.csv', 'r') as twitter_data:\n",
    "    csv_reader = csv.reader(twitter_data, delimiter=',')\n",
    "    line_count = 0\n",
    "    print(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_open = open('twitter-hate-speech-classifier-DFE-a845520.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-78-04237c89d8ee>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-78-04237c89d8ee>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test = .read(twitter_open)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test = .read(twitter_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
